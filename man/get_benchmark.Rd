% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dosearch.R
\name{get_benchmark}
\alias{get_benchmark}
\title{Benchmark a Specific Run of the Search}
\usage{
get_benchmark(x, run_again = FALSE, include_rules = FALSE)
}
\arguments{
\item{x}{An object of class \code{dosearch}.}

\item{run_again}{If \code{TRUE}, runs the search again in an attempt to obtain
the formula, for example if \code{control$formula} was \code{FALSE} in the call to
\code{\link[=dosearch]{dosearch()}}, but the query itself is identifiable.}

\item{include_rules}{A \code{logical} value. If \code{TRUE}, also benchmarks the time
taken by each inference rule separately.}
}
\value{
A \code{list} with one or two elements or \code{NULL}.
The first element of the list is always a numeric
value of the total time taken by the search in milliseconds.
The second is a numeric vector of the time taken by each inference rule
(in the internal C++ implementation) of the search in milliseconds
if \code{include_rules} is \code{TRUE}
}
\description{
Returns the benchmarking information of an object of class \code{dosearch}
returned by \code{\link[=dosearch]{dosearch()}}. If no benchmark is available, returns
\code{NULL}.
}
\examples{
data <- "P(x,y,z)"
query <- "P(y|do(x))"
graph <- "
  x -> y
  z -> x
  z -> y
"
x <- dosearch(data, query, graph, control = list(benchmark = FALSE))
get_benchmark(x, run_again = TRUE)
}
